{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration Notebook\n",
    "\n",
    "This notebook explores the collected Python functions dataset.\n",
    "\n",
    "**Contents:**\n",
    "1. Load and inspect raw data\n",
    "2. Class distribution (buggy vs clean)\n",
    "3. Code length analysis\n",
    "4. Sample functions\n",
    "5. Feature distribution (after preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "sys.path.append('..')  # Add project root to path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print('Libraries loaded successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "data_path = Path('../data/raw/functions.csv')\n",
    "\n",
    "if data_path.exists():\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f'Loaded {len(df)} samples')\n",
    "    print(f'\\nColumns: {list(df.columns)}')\n",
    "else:\n",
    "    print(f'Data file not found: {data_path}')\n",
    "    print('Please run data collection first: python -m src.data_collection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First few rows (truncate code for display)\n",
    "df_display = df.copy()\n",
    "df_display['code'] = df_display['code'].str[:100] + '...'\n",
    "df_display.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class counts\n",
    "class_counts = df['has_bug'].value_counts()\n",
    "print('Class Distribution:')\n",
    "print(f'  Clean (has_bug=0): {class_counts.get(0, 0)}')\n",
    "print(f'  Buggy (has_bug=1): {class_counts.get(1, 0)}')\n",
    "print(f'\\nClass Ratio: {class_counts.get(0, 0) / max(class_counts.get(1, 1), 1):.2f}:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Bar chart\n",
    "ax1 = axes[0]\n",
    "labels = ['Clean', 'Buggy']\n",
    "counts = [class_counts.get(0, 0), class_counts.get(1, 0)]\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "bars = ax1.bar(labels, counts, color=colors)\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Class Distribution')\n",
    "for bar, count in zip(bars, counts):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50, \n",
    "             str(count), ha='center', fontsize=12)\n",
    "\n",
    "# Pie chart\n",
    "ax2 = axes[1]\n",
    "ax2.pie(counts, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "ax2.set_title('Class Proportion')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Code Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines of code statistics\n",
    "print('Lines of Code Statistics:')\n",
    "print(df['lines_of_code'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution by class\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "ax1 = axes[0]\n",
    "for label, color, name in [(0, '#2ecc71', 'Clean'), (1, '#e74c3c', 'Buggy')]:\n",
    "    subset = df[df['has_bug'] == label]['lines_of_code']\n",
    "    if len(subset) > 0:\n",
    "        ax1.hist(subset, bins=50, alpha=0.6, label=name, color=color)\n",
    "ax1.set_xlabel('Lines of Code')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Distribution of Function Length')\n",
    "ax1.legend()\n",
    "\n",
    "# Box plot\n",
    "ax2 = axes[1]\n",
    "df.boxplot(column='lines_of_code', by='has_bug', ax=ax2)\n",
    "ax2.set_xlabel('Has Bug')\n",
    "ax2.set_ylabel('Lines of Code')\n",
    "ax2.set_title('Function Length by Class')\n",
    "ax2.set_xticklabels(['Clean', 'Buggy'])\n",
    "plt.suptitle('')  # Remove auto-generated title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Repository Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repository distribution\n",
    "print(f'Unique repositories: {df[\"repo\"].nunique()}')\n",
    "print('\\nTop 10 repositories:')\n",
    "df['repo'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repository stars distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "df['stars'].hist(bins=50, ax=ax, color='steelblue', edgecolor='white')\n",
    "ax.set_xlabel('Repository Stars')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Distribution of Repository Stars')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sample Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_function(code, title='Function'):\n",
    "    \"\"\"Pretty print a function with syntax highlighting.\"\"\"\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'{title}')\n",
    "    print('='*60)\n",
    "    print(code)\n",
    "    print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample clean functions\n",
    "clean_samples = df[df['has_bug'] == 0].sample(min(3, len(df[df['has_bug']==0])), random_state=42)\n",
    "\n",
    "print('SAMPLE CLEAN FUNCTIONS')\n",
    "for i, (_, row) in enumerate(clean_samples.iterrows()):\n",
    "    display_function(\n",
    "        row['code'], \n",
    "        f\"Clean Function {i+1}: {row['function_name']} (from {row['repo']})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample buggy functions (if any)\n",
    "buggy_samples = df[df['has_bug'] == 1]\n",
    "\n",
    "if len(buggy_samples) > 0:\n",
    "    buggy_samples = buggy_samples.sample(min(3, len(buggy_samples)), random_state=42)\n",
    "    print('SAMPLE BUGGY FUNCTIONS')\n",
    "    for i, (_, row) in enumerate(buggy_samples.iterrows()):\n",
    "        display_function(\n",
    "            row['code'], \n",
    "            f\"Buggy Function {i+1}: {row['function_name']} (from {row['repo']})\"\n",
    "        )\n",
    "else:\n",
    "    print('No buggy functions in dataset yet.')\n",
    "    print('Run data collection to collect buggy functions from bug fix commits.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Processed Features Analysis\n",
    "\n",
    "Run this section after preprocessing: `python -m src.preprocessing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data if available\n",
    "processed_dir = Path('../data/processed')\n",
    "metadata_path = processed_dir / 'metadata.json'\n",
    "\n",
    "if metadata_path.exists():\n",
    "    with open(metadata_path) as f:\n",
    "        metadata = json.load(f)\n",
    "    print('Preprocessing Metadata:')\n",
    "    print(json.dumps(metadata, indent=2))\n",
    "else:\n",
    "    print('Processed data not found.')\n",
    "    print('Run preprocessing first: python -m src.preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and visualize features\n",
    "features_path = processed_dir / 'features.npz'\n",
    "feature_names_path = processed_dir / 'feature_names.json'\n",
    "\n",
    "if features_path.exists() and feature_names_path.exists():\n",
    "    features = np.load(features_path)['features']\n",
    "    with open(feature_names_path) as f:\n",
    "        feature_names = json.load(f)\n",
    "    \n",
    "    print(f'Feature matrix shape: {features.shape}')\n",
    "    print(f'Number of features: {len(feature_names)}')\n",
    "    print(f'\\nFeature names: {feature_names}')\n",
    "else:\n",
    "    print('Feature files not found. Run preprocessing first.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature statistics\n",
    "if features_path.exists():\n",
    "    features_df = pd.DataFrame(features, columns=feature_names)\n",
    "    print('Feature Statistics (first 10):')\n",
    "    features_df.iloc[:, :10].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature distributions\n",
    "if features_path.exists():\n",
    "    # Select first 9 features for visualization\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (ax, name) in enumerate(zip(axes, feature_names[:9])):\n",
    "        ax.hist(features[:, i], bins=50, edgecolor='white')\n",
    "        ax.set_title(name)\n",
    "        ax.set_xlabel('Value')\n",
    "        ax.set_ylabel('Frequency')\n",
    "    \n",
    "    plt.suptitle('Feature Distributions', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature correlation heatmap\n",
    "if features_path.exists():\n",
    "    # Calculate correlation matrix (first 15 features)\n",
    "    n_features = min(15, len(feature_names))\n",
    "    corr_matrix = np.corrcoef(features[:, :n_features].T)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(\n",
    "        corr_matrix, \n",
    "        xticklabels=feature_names[:n_features],\n",
    "        yticklabels=feature_names[:n_features],\n",
    "        cmap='RdBu_r',\n",
    "        center=0,\n",
    "        annot=True,\n",
    "        fmt='.2f',\n",
    "        square=True\n",
    "    )\n",
    "    plt.title('Feature Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Split Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify train/val/test split\n",
    "train_idx_path = processed_dir / 'train_indices.npy'\n",
    "val_idx_path = processed_dir / 'val_indices.npy'\n",
    "test_idx_path = processed_dir / 'test_indices.npy'\n",
    "labels_path = processed_dir / 'labels.npy'\n",
    "\n",
    "if all(p.exists() for p in [train_idx_path, val_idx_path, test_idx_path, labels_path]):\n",
    "    train_idx = np.load(train_idx_path)\n",
    "    val_idx = np.load(val_idx_path)\n",
    "    test_idx = np.load(test_idx_path)\n",
    "    labels = np.load(labels_path)\n",
    "    \n",
    "    print('Data Split:')\n",
    "    print(f'  Train: {len(train_idx)} samples ({len(train_idx)/len(labels)*100:.1f}%)')\n",
    "    print(f'  Validation: {len(val_idx)} samples ({len(val_idx)/len(labels)*100:.1f}%)')\n",
    "    print(f'  Test: {len(test_idx)} samples ({len(test_idx)/len(labels)*100:.1f}%)')\n",
    "    \n",
    "    print('\\nClass balance in each split:')\n",
    "    for name, idx in [('Train', train_idx), ('Val', val_idx), ('Test', test_idx)]:\n",
    "        buggy = labels[idx].sum()\n",
    "        clean = len(idx) - buggy\n",
    "        print(f'  {name}: {buggy} buggy ({buggy/len(idx)*100:.1f}%), {clean} clean ({clean/len(idx)*100:.1f}%)')\n",
    "else:\n",
    "    print('Split files not found. Run preprocessing first.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook explored:\n",
    "- Raw data structure and content\n",
    "- Class distribution (buggy vs clean)\n",
    "- Code length patterns\n",
    "- Repository sources\n",
    "- Sample functions\n",
    "- Extracted features (if preprocessing completed)\n",
    "- Data split verification\n",
    "\n",
    "**Next Steps:**\n",
    "1. If no buggy functions: Continue running data collection\n",
    "2. If data collected: Run preprocessing (`python -m src.preprocessing`)\n",
    "3. After preprocessing: Train the model (`python -m src.train`)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
